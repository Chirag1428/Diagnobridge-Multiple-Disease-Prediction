{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "heart1: (918, 12)\n",
            "heart2: (1888, 14)\n",
            "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
            "0   40   M           ATA        140          289          0     Normal    172   \n",
            "1   49   F           NAP        160          180          0     Normal    156   \n",
            "\n",
            "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
            "0              N      0.0       Up             0  \n",
            "1              N      1.0     Flat             1  \n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalachh  exang  oldpeak  \\\n",
            "0   63    1   3       145   233    1        0       150      0      2.3   \n",
            "1   37    1   2       130   250    0        1       187      0      3.5   \n",
            "\n",
            "   slope  ca  thal  target  \n",
            "0      0   0     1       1  \n",
            "1      0   0     2       1  \n"
          ]
        }
      ],
      "source": [
        "# 1. LOAD BOTH HEART DATASETS\n",
        "# ============================================================\n",
        "heart1 = pd.read_csv(\"../dataset/heart_disease/heart.csv\")            # 918 x 12\n",
        "heart2 = pd.read_csv(\"../dataset/heart_disease/heart_dataset.csv\")    # 1888 x 14\n",
        "\n",
        "print(\"heart1:\", heart1.shape)\n",
        "print(\"heart2:\", heart2.shape)\n",
        "print(heart1.head(2))\n",
        "print(heart2.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. CLEAN & ALIGN COLUMN NAMES\n",
        "# ============================================================\n",
        "heart1 = heart1.rename(columns={\n",
        "    \"HeartDisease\": \"target\"\n",
        "})\n",
        "\n",
        "heart2 = heart2.rename(columns={\n",
        "    \"age\": \"Age\",\n",
        "    \"sex\": \"Sex\",\n",
        "    \"trestbps\": \"RestingBP\",\n",
        "    \"chol\": \"Cholesterol\",\n",
        "    \"thalachh\": \"MaxHR\",\n",
        "    \"exang\": \"ExerciseAngina\",\n",
        "    \"oldpeak\": \"Oldpeak\",\n",
        "    \"slope\": \"ST_Slope\",\n",
        "    \"target\": \"target\"\n",
        "})\n",
        "\n",
        "if heart1[\"ExerciseAngina\"].dtype == object:\n",
        "    heart1[\"ExerciseAngina\"] = heart1[\"ExerciseAngina\"].map({\"Y\": 1, \"N\": 0})\n",
        "\n",
        "heart1[\"target\"] = heart1[\"target\"].astype(int)\n",
        "heart2[\"target\"] = heart2[\"target\"].astype(int)\n",
        "\n",
        "heart2[\"ExerciseAngina\"] = heart2[\"ExerciseAngina\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined: (2806, 9)\n"
          ]
        }
      ],
      "source": [
        "# 3. CREATE FINAL 8 FEATURES\n",
        "# ============================================================\n",
        "FEATURES = [\n",
        "    \"Age\",\n",
        "    \"RestingBP\",\n",
        "    \"Cholesterol\",\n",
        "    \"MaxHR\",\n",
        "    \"Oldpeak\",\n",
        "    \"ChestPainType\",\n",
        "    \"ST_Slope\",\n",
        "    \"Thal\"\n",
        "]\n",
        "\n",
        "heart1[\"Thal\"] = \"unknown\"     # missing in dataset 1\n",
        "heart1[\"ChestPainType\"] = heart1[\"ChestPainType\"].astype(str)\n",
        "heart1[\"ST_Slope\"] = heart1[\"ST_Slope\"].astype(str)\n",
        "\n",
        "heart2[\"ChestPainType\"] = heart2[\"cp\"].astype(str)\n",
        "heart2[\"ST_Slope\"] = heart2[\"ST_Slope\"].astype(str)\n",
        "heart2[\"Thal\"] = heart2[\"thal\"].astype(str)\n",
        "\n",
        "df1 = heart1[FEATURES + [\"target\"]].copy()\n",
        "df2 = heart2[FEATURES + [\"target\"]].copy()\n",
        "\n",
        "combined = pd.concat([df1, df2], ignore_index=True)\n",
        "print(\"Combined:\", combined.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. CLEAN DATA TYPES\n",
        "# ============================================================\n",
        "numeric_cols = [\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
        "cat_cols = [\"ChestPainType\", \"ST_Slope\", \"Thal\"]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    combined[col] = pd.to_numeric(combined[col], errors=\"coerce\")\n",
        "    combined[col] = combined[col].fillna(combined[col].median())\n",
        "\n",
        "for col in cat_cols:\n",
        "    combined[col] = combined[col].astype(str)\n",
        "    combined[col] = combined[col].fillna(\"unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Balanced:\n",
            "target\n",
            "1    1321\n",
            "0    1321\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 5. BALANCE DATASET (UPSAMPLE MINORITY 1:1)\n",
        "# ============================================================\n",
        "majority = combined[combined[\"target\"] == 0]\n",
        "minority = combined[combined[\"target\"] == 1]\n",
        "\n",
        "minority_up = resample(minority, replace=True,\n",
        "                       n_samples=len(majority),\n",
        "                       random_state=42)\n",
        "\n",
        "balanced = pd.concat([majority, minority_up]).sample(frac=1, random_state=42)\n",
        "\n",
        "print(\"\\nBalanced:\")\n",
        "print(balanced[\"target\"].value_counts())\n",
        "\n",
        "X = balanced[FEATURES]\n",
        "y = balanced[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. PREPROCESSOR (SCALING + ONE-HOT)\n",
        "# ============================================================\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. DEFINE STACKING MODEL\n",
        "# ============================================================\n",
        "estimators = [\n",
        "    (\"rf\", RandomForestClassifier(n_estimators=300, random_state=42)),\n",
        "    (\"xgb\", XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42\n",
        "    ))\n",
        "]\n",
        "\n",
        "stack = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5,\n",
        "    stack_method=\"predict_proba\"\n",
        ")\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"stack\", stack)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Accuracy: 0.9443632926619694\n",
            "CV ROC-AUC: 0.9869896759187068\n",
            "CV F1: 0.9453384709444645\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "cv_auc = cross_val_score(model, X, y, cv=skf, scoring='roc_auc')\n",
        "cv_f1 = cross_val_score(model, X, y, cv=skf, scoring='f1')\n",
        "\n",
        "print(\"CV Accuracy:\", cv_accuracy.mean())\n",
        "print(\"CV ROC-AUC:\", cv_auc.mean())\n",
        "print(\"CV F1:\", cv_f1.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. TRAIN-TEST SPLIT\n",
        "# ============================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FINAL STACKING MODEL RESULTS ===\n",
            "Accuracy: 0.943289224952741\n",
            "[[243  22]\n",
            " [  8 256]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94       265\n",
            "           1       0.92      0.97      0.94       264\n",
            "\n",
            "    accuracy                           0.94       529\n",
            "   macro avg       0.94      0.94      0.94       529\n",
            "weighted avg       0.94      0.94      0.94       529\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 9. TRAIN + EVALUATE\n",
        "# ============================================================\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\n=== FINAL STACKING MODEL RESULTS ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved → ../saved_models/heart_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# 10. SAVE MODEL\n",
        "# ============================================================\n",
        "artifacts = {\n",
        "    \"model\": model,\n",
        "    \"feature\": FEATURES\n",
        "}\n",
        "\n",
        "os.makedir(\"../saved_mdl\", exist_ok=True)\n",
        "joblib.dump(artifacts, \"../saved_mdl/heart_model.pkl\")\n",
        "\n",
        "print(\"\\nSaved → ../saved_mdl/heart_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
