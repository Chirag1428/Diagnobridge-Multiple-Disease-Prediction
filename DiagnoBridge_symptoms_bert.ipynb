{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf72161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 4050 Laptop GPU')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0908b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from transformers import IntervalStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4dff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4920, 134)\n",
      "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
      "0        1          1                     1                    0          0   \n",
      "1        0          1                     1                    0          0   \n",
      "2        1          0                     1                    0          0   \n",
      "3        1          1                     0                    0          0   \n",
      "4        1          1                     1                    0          0   \n",
      "\n",
      "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  scurring  \\\n",
      "0       0           0             0        0                 0  ...         0   \n",
      "1       0           0             0        0                 0  ...         0   \n",
      "2       0           0             0        0                 0  ...         0   \n",
      "3       0           0             0        0                 0  ...         0   \n",
      "4       0           0             0        0                 0  ...         0   \n",
      "\n",
      "   skin_peeling  silver_like_dusting  small_dents_in_nails  \\\n",
      "0             0                    0                     0   \n",
      "1             0                    0                     0   \n",
      "2             0                    0                     0   \n",
      "3             0                    0                     0   \n",
      "4             0                    0                     0   \n",
      "\n",
      "   inflammatory_nails  blister  red_sore_around_nose  yellow_crust_ooze  \\\n",
      "0                   0        0                     0                  0   \n",
      "1                   0        0                     0                  0   \n",
      "2                   0        0                     0                  0   \n",
      "3                   0        0                     0                  0   \n",
      "4                   0        0                     0                  0   \n",
      "\n",
      "          prognosis  Unnamed: 133  \n",
      "0  Fungal infection           NaN  \n",
      "1  Fungal infection           NaN  \n",
      "2  Fungal infection           NaN  \n",
      "3  Fungal infection           NaN  \n",
      "4  Fungal infection           NaN  \n",
      "\n",
      "[5 rows x 134 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD BASE DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"../dataset/symptom/training_data.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# symptom columns = all except 'prognosis'\n",
    "symptom_cols = [c for c in df.columns if c != \"prognosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c124f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example generated texts:\n",
      "                                        symptom_text         prognosis\n",
      "0  Patient reports itching, skin rash, nodal skin...  Fungal infection\n",
      "1  Patient reports skin rash, nodal skin eruption...  Fungal infection\n",
      "2  Patient reports itching, nodal skin eruptions ...  Fungal infection\n",
      "3  Patient reports itching, skin rash and dischro...  Fungal infection\n",
      "4  Patient reports itching, skin rash and nodal s...  Fungal infection\n"
     ]
    }
   ],
   "source": [
    "# 2. CONVERT BINARY SYMPTOMS â†’ TEXT\n",
    "# =========================\n",
    "\n",
    "def row_to_text(row):\n",
    "    active = [col.replace(\"_\", \" \").strip() for col in symptom_cols if row[col] == 1]\n",
    "    if not active:\n",
    "        return \"Patient reports no significant symptoms.\"\n",
    "    if len(active) == 1:\n",
    "        return f\"Patient reports {active[0]}.\"\n",
    "    else:\n",
    "        body = \", \".join(active[:-1])\n",
    "        last = active[-1]\n",
    "        return f\"Patient reports {body} and {last}.\"\n",
    "\n",
    "df[\"symptom_text\"] = df.apply(row_to_text, axis=1)\n",
    "\n",
    "print(\"\\nExample generated texts:\")\n",
    "print(df[[\"symptom_text\", \"prognosis\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa31f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of diseases: 41\n",
      "Classes: ['(vertigo) Paroymsal  Positional Vertigo', 'AIDS', 'Acne', 'Alcoholic hepatitis', 'Allergy', 'Arthritis', 'Bronchial Asthma', 'Cervical spondylosis', 'Chicken pox', 'Chronic cholestasis', 'Common Cold', 'Dengue', 'Diabetes ', 'Dimorphic hemmorhoids(piles)', 'Drug Reaction', 'Fungal infection', 'GERD', 'Gastroenteritis', 'Heart attack', 'Hepatitis B', 'Hepatitis C', 'Hepatitis D', 'Hepatitis E', 'Hypertension ', 'Hyperthyroidism', 'Hypoglycemia', 'Hypothyroidism', 'Impetigo', 'Jaundice', 'Malaria', 'Migraine', 'Osteoarthristis', 'Paralysis (brain hemorrhage)', 'Peptic ulcer diseae', 'Pneumonia', 'Psoriasis', 'Tuberculosis', 'Typhoid', 'Urinary tract infection', 'Varicose veins', 'hepatitis A']\n"
     ]
    }
   ],
   "source": [
    "# 3. LABEL ENCODING\n",
    "# =========================\n",
    "le = LabelEncoder()\n",
    "df[\"label_id\"] = le.fit_transform(df[\"prognosis\"])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(\"\\nNumber of diseases:\", num_classes)\n",
    "print(\"Classes:\", list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d607c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3936\n",
      "Val size: 984\n"
     ]
    }
   ],
   "source": [
    "# 4. TRAIN/VALIDATION SPLIT\n",
    "# =========================\n",
    "train_df, val_df = train_test_split(\n",
    "    df[[\"symptom_text\", \"label_id\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label_id\"]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", train_df.shape[0])\n",
    "print(\"Val size:\", val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ed6c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e0e857e0c24913870de48998bcdf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2269ea260d43bb9463c74d1d397063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880a66de28664532ac5ce2bb0c0cc47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff30213575f4db08356f7f0cf3cd8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. TOKENIZER & MODEL\n",
    "# =========================\n",
    "model_name = \"distilbert-base-uncased\"  # lighter than full BERT\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_batch(train_df[\"symptom_text\"])\n",
    "val_encodings = tokenize_batch(val_df[\"symptom_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff968b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7febbb6fedcb4f69b52cc5dd908a3558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6. TORCH DATASETS\n",
    "# =========================\n",
    "class SymptomsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SymptomsDataset(train_encodings, train_df[\"label_id\"].values)\n",
    "val_dataset   = SymptomsDataset(val_encodings,   val_df[\"label_id\"].values)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697e460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22493/4104202671.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='492' max='492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [492/492 01:08, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.269800</td>\n",
       "      <td>0.300263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=492, training_loss=0.507337248422266, metrics={'train_runtime': 69.6928, 'train_samples_per_second': 225.906, 'train_steps_per_second': 7.06, 'total_flos': 252724745866752.0, 'train_loss': 0.507337248422266, 'epoch': 4.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. TrainingArguments + Trainer\n",
    "# =========================\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Metric function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1}\n",
    "\n",
    "# GPU-optimized training settings\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_symptom_results\",\n",
    "    num_train_epochs=4,                \n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=5e-5,\n",
    "    eval_strategy=\"epoch\",        # <-- FIXED HERE\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d19a6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3002631962299347,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_macro_f1': 1.0,\n",
       " 'eval_runtime': 0.755,\n",
       " 'eval_samples_per_second': 1303.266,\n",
       " 'eval_steps_per_second': 21.191,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Evaluate\n",
    "# =========================\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc80bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved DistilBERT symptom NLP model to: ../saved_models/bert_symptom_nlp\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "save_dir = \"../saved_mdl/bert_symptom_nlp\"\n",
    "os.makedir(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model + tokenizer in HuggingFace format\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(\n",
    "    {\"label_encoder\": le},\n",
    "    os.path.join(save_dir, \"label_encoder.pkl\")\n",
    ")\n",
    "\n",
    "print(\"\\nSaved DistilBERT symptom NLP model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ea4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
